%%
%% This is file `sample-sigplan.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,proceedings,bibtex,sigplan')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigplan.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[sigconf, anonymous]{acmart}


%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmlicensed}
\copyrightyear{2018}
\acmYear{2018}
\acmDOI{XXXXXXX.XXXXXXX}

%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[Conference acronym 'XX]{Make sure to enter the correct
  conference title from your rights confirmation emai}{June 03--05,
  2018}{Woodstock, NY}
%%
%%  Uncomment \acmBooktitle if the title of the proceedings is different
%%  from ``Proceedings of ...''!
%%
%%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%%  June 03--05, 2018, Woodstock, NY}
\acmISBN{978-1-4503-XXXX-X/18/06}

%% get rid of this for the final version
\usepackage{todonotes}
\usepackage{listingsutf8}
\setlength {\marginparwidth }{2cm} %This is for todod
\usepackage{tikz}
\usetikzlibrary{positioning}
\usepackage{cryptocode}
\usepackage{lstcoq}
\usepackage[utf8]{inputenc}
%% End of get rid of this for the final version


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{One Proof, Many Implementations of Certified $\Sigma$-Protocols}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.

\author{Mukesh Tiwari}
\affiliation{%
 \institution{Swansea University}
 \country{United Kingdom}}
 \email{mukesh.tiwari@swansea.ac.uk}

\author{Berry Schoenmakers}
\affiliation{%
  \institution{TU Eindhoven, Eindhoven}
  \country{The Netherlands}}
  \email{l.a.m.schoenmakers@tue.nl}


\author{Bas Spitters}
\affiliation{%
  \institution{Aarhus University}
  \country{Denmark}}
\email{spitters@cs.au.dk}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Tiwari et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
  $\Sigma$-protocols are a core building block in a wide range of privacy-preserving applications, but 
  one particular application where they have found a widespread adoption is electronic voting.
  They remain a popular choice in electronic voting to maintain privacy 
  and verifiability of elections and are still used in prominent electronic voting systems such as 
  Helios, Belenois, and SwissPost. However, existing implementations of $\Sigma$-protocols have two 
  critical shortcomings: (i) the same code must be written multiple times, once for the front-end (JavaScript/TypeScript)
  and once for the back-end (Python/OCaml/Java), which is error-prone because the front-end and back-end codes are often written by different developers, leading to inconsistencies and bugs,
  and (ii) none of these implementations provide formal security guarantees. 
  
  In this paper, we present a certified formalisation of a comprehensive library of $\Sigma$-protocols 
  in the Rocq theorem prover, and we formally prove (special) soundness, completeness, and 
  (special honest-verifier) zero-knowledge properties. Our generic formalisation over abstract vector spaces enables us to uniformly express and compose a wide class of discrete-logarithm-based $\Sigma$-protocols, while remaining independent of any concrete group or cryptographic instantiation. Moreover, the constructive nature of our formalisation allow us to
  extract and compile to executable implementations in OCaml, Rust, and WebAssembly and thereby
  eliminating code duplication. We demonstrate the practical applicability of our 
  framework by implementing a voting server and client for the Approval voting and 
  IACR tallysheet verifier.  Our certified cryptographic library provides a foundation for 
  building formally verified privacy-preserving applicatons. 


 


\end{abstract}


\begin{CCSXML}
<ccs2012>
  <concept>
      <concept_id>10002978.10002986.10002990</concept_id>
      <concept_desc>Security and privacy~Logic and verification</concept_desc>
      <concept_significance>500</concept_significance>
      </concept>
</ccs2012>
\end{CCSXML}
  
\ccsdesc[500]{Security and privacy~Logic and verification}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Sigma Protocol, Formal Verification, Rocq, Cryptography, Zero-Knowledge Proof}



%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle




\section{Introduction}
$\Sigma$-protocols are a fundamental class of zero-knowledge proof systems that enable a prover to convince a verifier of the correctness of a statement without revealing any additional information beyond its validity. Owing to their simplicity and security guarantees, $\Sigma$-protocols have become a core building block in a wide range of privacy-preserving applications such as anonymous credentials \cite{10.1145/2660267.2660328}, 
password-authenticated key exchange \cite{10.5555/2022815.2022838}, 
signature \cite{10.1007/0-387-34805-0_22}, threshold signature \cite{10.1007/978-3-030-81652-0_2}, etc. In the context of electronic voting, $\Sigma$-protocols play a particularly central role: they are used to prove that ballots are well-formed, that encryptions encode valid votes, that mix-nets correctly shuffle encrypted ballots, and that tallies are computed honestly, all without compromising voter privacy. These proofs underpin end-to-end verifiability by allowing voters and independent observers to publicly verify the integrity of each stage of the election while preserving ballot secrecy. As a result, the correctness and trustworthiness of $\Sigma$-protocol implementations directly impact the security of modern electronic voting systems which makes them a natural target for rigorous formal verification.

\textcolor{red}{Is this flow good between the previous and the next paragraph?}

Electronic voting offers convenience and efficiency in electoral processes, potentially improving 
accessibility for disabled voters, increasing participation among overseas voters, and lowering 
the costs associated with conducting elections. Moreover,
they can streamline the voting process, reduce administrative burdens, and enable 
faster tallying of results. However, electronic voting also brings significant 
challenges in ensuring the privacy and verifiability, a must for free-and-fair elections, of the voting process. Therefore, 
privacy and verifiability are two crucial elements that a voting system must ensure.
In a paper-ballot election, privacy is maintained by 
ensuring that no identifying information is present on a ballot that links it to a particular voter, 
and verifiability is achieved through scrutineers closely observing various electoral processes, 
including the counting of ballots. In order to have a similar effect in electronic voting, encryption 
is employed to safeguard the privacy of voter choices, while publicly verifiable evidence 
(such as zero-knowledge proofs) allows voters and independent observers to verify the integrity of 
the voting process. However, no matter how advanced the cryptographic techniques, they are useless 
if their software implementation contains bugs. In fact, 
the Swiss Federal Chancellery suspended electronic voting in 2019 because of 
a fatal software bug in the implementation of a cryptographic primitive 
that allowed someone to change the cast votes without being detected \cite{9152765}.
It only resumed in 2023 after getting feedbacks from academic 
community \cite{swiss_evoting_chronik} about the various components used in 
the electronic voting software. However, it is not an isolated  
instance where bugs have been found in a voting software, e.g., 
Voatz \cite{255334} (used in West Virginia, USA election),
Democracy Live Online Voting System \cite{263858} 
(used in Delaware, West Virginia, and New Jersey, USA election), 
Moscow Internet Voting System \cite{10.1007/978-3-030-51280-4_3}
(used in Russia election), and iVote System \cite{10.1007/978-3-319-22270-7_3, 10.1145/3014812.3014837} 
(used in New South Wales, Australia election). 
These unfortunate situations can largely be attributed to two factors: 
(i) closed source code (proprietary artifacts) because most of these bugs were 
discovered by researchers who inspected the code after they were made public, and 
(ii) software testing which is inadequate to rule out all the bugs 
from a software. Therefore, to avoid the situations like this, 
an electronic voting system must adhere to \textit{software independence}\cite{rivest2008notion}:
\begin{quote}
  A voting system is software-independent if an
  (undetected) change or error in its software cannot
  cause an undetectable change or error in an
  election outcome. 
\end{quote}
\noindent
Therefore, many electronic voting systems follow the principals 
of \textit{end-to-end verifiability}. End-to-end verifiability is 
defined as: 
\begin{itemize}
  \item \textit{cast-as-intended}: voters get proof that the electronic ballot accurately reflects their choices.
  \item \textit{collected-as-cast}: the election authority provides proof that the electronic ballots are received without tampering.
  \item \textit{counted-as-collected}: the election authority provides proof that the results are based on correctly counting all received ballots.
\end{itemize} 


Finally, voters and scrutineers inspect these proofs and accept or reject the election results based on 
the verification of these proofs. In practice, this means that during the execution of an election, 
electronic voting software generates data, and voters and scrutineers verify the conformity of 
this data using independently written computer programs. The rationale is that if there is 
any discrepancy in the electronic voting system, at least one scrutineer or voter would detect it.
It is important to note that end-to-end verifiability is a valuable feature because it 
allows for the verification of the election results by checking the proofs of correctness 
once the election has concluded. This ensures that the election process was conducted 
properly and that the results are accurate, but it is only in action during or after the voting has taken place.
However, can we use it as a guiding principle to develop an electronic voting software, way before 
an election? The answer is yes; we can use a formal language to express end-to-end verifiability, or parts of 
it, and develop various components of an electronic voting 
software in this formal language. This process is called formal verification, or correct-by-construction,
and it ensures that the software always produces valid proofs that 
are accepted by voters and scrutineers every time. In other words, formal verification
can be employed to develop reliable electronic voting software.
In fact, formal verification has emerged as a promising solution 
to eliminate potential bugs from software, and in recent years it has been increasingly 
adopted in real-world software applications \cite{10.1145/1111037.1111042}, 
including cryptography \cite{8835346,10.1145/3133956.3134043,190894,10.1145/2701415,
10.1145/2660267.2660370,10.1145/3319535.3363211}.

In this paper, we present a certified implementation of $\Sigma$-protocols and their compositions in 
the formal language of the Rocq proof assistant. Our formalisation encompasses the basic Schnorr protocol, 
Chaum-Pedersen, Okamoto, Pedersen linear relation, encryption proofs, and compositional constructions including Parallel-$\Sigma$, 
And-$\Sigma$, Or-$\Sigma$, Eq-$\Sigma$, and Neq-$\Sigma$ protocols. For each protocol, we formally prove 
completeness, special soundness, and special honest-verifier zero-knowledge properties.
Our formalisation is developed 
generically over abstract vector spaces, enabling uniform expression and composition of discrete-logarithm-based 
$\Sigma$-protocols while remaining independent of any concrete group or cryptographic instantiation. Additionally, we have implemented efficient arithmetic procedures for prime fields and Schnorr groups (including the Helios parameters, 
with formally verified primality proofs for the 2048-bit prime $p$ and 256-bit prime $q$) to 
ensure our library is practically usable. \textcolor{blue}{Finally, we extract executable OCaml,, Rust, and WebAssembly code from our certified 
Rocq implementation and demonstrate its practical applicability through a complete Helios election verifier that 
validates real-world IACR elections (2023, 2024), verifying ballot proofs, tallying, and trustee decryption proofs}. To the best of our knowledge,  this is the first formal verification of $\Sigma$-protocols that can be extracted to 
WebAssembly, Rust, and OCaml from Rocq proofs. Our proofs can be accessed from \url{https://anonymous.4open.science/r/SigmaProtocol-EBA5/README.md}, which contains 30,000 lines of Rocq proofs.

\subsection{Outline}
\textcolor{red}{rewrite this once the paper is finished.}
The rest of the paper is organised as follows: in section \ref{sigma_protocol}
we explain the idea of zero-knowledge proof and sigma protocol. 
Section \ref{coq_theorem} contains a brief introduction to 
the Coq theorem prover, MetaCoq, Coq encoding of the Schnorr protocol, 
uniform probability distribution model, modular arithmetic, Fiat-Shamir transform,
and reasoning about the complexity of extractor and simulator. 
In section \ref{case_studies} we show how our library can be used 
for encoding $\Sigma$-protocol used in Helios, Belenois, and SwissPost. 
Finally, section \ref{rel_work} concludes the related work, limitation of 
our work, and future direction. 



\section{Sigma Protocol}\label{sigma_protocol}
Despite the recent growth and popularity of zero-knowledge succinct 
argument of knowledge (ZkSNARK), $\Sigma$-protocol remains a
leading cryptographic proof system in privacy-preserving voting systems. 
$\Sigma$-protocol is used in Helios --a widely popular voting system-- \cite{adida2008helios}, 
Belenois --used in French elections for overseas 
voters\footnote{VVFE, used in French elections, is a derivative of (part of) Belenios and 
inherited all the zero-knowledge proofs from Belenois. \url{https://gitlab.inria.fr/vvfe/vvfe}}-- \cite{cortier2023french}, and 
SwissPost --used in Swiss elections for overseas voters-- voting 
systems \cite{10.1007/978-3-031-15911-4_4}. 
Moreover, recently zero-knowledge proof community started a movement to standardise
the sigma protocol \cite{ZKProof}.
One of the main reasons for its popularity in privacy-preserving voting systems is its
efficiency and well-understood security.


%\textbf{Introduce here that sigma protocol is efficient and simple and all other details about sigma protocol.} 
Zero-knowledge proofs were first studied by Goldwasser, Micali, and Rackoff \cite{10.1145/22145.22178} and 
are possible for all problems in $NP$ \cite{10.1145/116825.116852}. Recall that $NP$ is the class of 
problems that have efficient verifiers; that is, for a given problem in the $NP$ class, there is 
a polynomial-time algorithm that can verify whether a given solution, or witness, to the problem is correct or not.
More formally, for a given binary $NP$-relation $R$ and a statement $x$, zero-knowledge proof allows a prover 
$P$ to convince a verifier $V$ that they posses a witness $w$ --polynomial in length of $x$-- such 
that ($x$, $w$) $\in$ $R$. To achieve this, $P$ and $V$ engage in a 
interactive protocol and  at the end of the protocol $V$ either accepts or rejects the proofs.
$\Sigma$-protocol  is an efficient three move zero-knowledge proof where the 
verifier is assumed to be honest and characterised by completeness, (special) soundness, and 
(special honest-verifier) zero-knowledge. More formally: 
\begin{itemize}
  \item \textbf{Completeness:}
  when $P$ and $V$ follow the protocol, $V$ always accepts. 
  In other words, if $P$ knows $w$ for $x$ such that ($x$, $w$) $\in$ $R$,  
  then $P$ can successfully construct a proof $(a, c, r)$ that always passes the verification equation, 
  i.e., $V$ accepts. 

\item \textbf{Special soundness:}
there exists a probabilistic polynomial-time extractor $E$ which given 
two accepting transcripts $(a, c, r)$ and $(a, c', r')$ for $x$, 
it can extract a witness $w$ such that $(x, w) \in R$. In other words, 
if $P$ does not know $w$ for $x$ then it cannot construct a proof 
$(a, c, r)$ that will passes the verification check. 
\item \textbf{Special honest-verifier zero-knowledge.}
There exists a probabilistic polynomial-time simulator $S$ such that, for any $v \in L_R$ and any challenge $c \in C$, $S$ outputs a transcript $(a; c; r)$ that is distributed exactly as in a real conversation between an honest prover $P$ (using any witness $w$ with $(v,w) \in R$) and an honest verifier $V$ on common input $v$ and challenge $c$. Moreover, for any $v \notin L_R$, the simulator $S$ is just required to produce an arbitrary accepting conversations $(a; c; r)$ for the given challenge $c \in C$.
\end{itemize}








Sigma protocol was first defined by Ronald Cramer \cite{cramer1996modular} 
and the first efficient sigma protocol was introduced by Schnorr in \cite{schnorr1991efficient}. 
Even though there exists many sigma protocols, the Schnorr protocol is used extensively in privacy-preserving voting systems, e.g, Helios, Belenois, SwissPost, etc. Therefore, 
our formalisation is geared towards the Schnorr protocol. 
Moreover, we formalise the \(n\)-ary composition of Schnorr \(\Sigma\)-protocols, instantiating Parallel, And, Or, Eq, and Neq constructions for arbitrary \(n\). In addition, we also formalise the Chaum-Pedersen protocol for proving equality of discrete logarithms, the Okamoto protocol for linear relations over multiple generators, encryption proofs (demonstrating that ElGamal ciphertexts encrypt specific values), decryption proofs (verifying correct decryption by election trustees), and the Pedersen Linear Relation protocol for proving knowledge of committed values satisfying linear constraints.
Ideally, given the abstraction of our formlisation (\textit{vector space}), we could have 
abstracted the sigma protocol and their composition in a generic way \cite{10.1007/978-3-642-02384-2_17},
but we decided to focus on the Schnorr protocol and its composition to ensure familiar APIs 
for electronic voting in WebAssembly and Rust. However, we have not seen 
much use of Neq in the privacy-preserving voting systems, at least in the existing voting systems 
such as Helios, Belenois, and SwissPost.  




\section{The Rocq Theorem Prover}\label{coq_theorem}
The Rocq theorem prover \cite{the_coq_development_team} is a computer program that interacts with users, 
enabling them to encode mathematical definitions, express specifications (true statements) about 
their definitions, and formally prove that the definitions imply the specifications. 
A user first defines their mathematical object (definition) and then figures 
out some true statements (specifications) about 
that object. Once the user has definition and specifications, they need to prove 
that the definition satisfies the specifications 
(proof writing). In general, amongst these three steps, 
the proof writing step is the most challenging and important step. 
During the proof writing, an user interacts with Rocq
via \emph{tactics}, a domain specific language 
to ease the proof writing. Even though Rocq  
provides some amount of automation and proof 
search, most of the time it requires human assistance to finish the proof. 
It is one the most popular and robust theorem, and
one of reasons for its popularity is 
dependent types that makes it possible to encode
any mathematical statement in its logic.
It has been used to verify many real world software projects and mathematical 
artefacts. For example, Coq has been used to 
formally verify CompCert \cite{10.1145/1111037.1111042}, 
a C compiler used by many companies\footnote{https://www.absint.com/partners.htm}, 
Fiat-Crypto \cite{8835346} 
used in BoringSSL --a cryptographic library used in Chrome, Android, 
and CloudFlare--, ConCert \cite{10.1145/3372885.3373829}, 
a smart contract certification framework, etc. \textcolor{red}{FIXME: More examples}


\subsection{Web Assembly and Rust from the Roq Formalisation}
  Bas






\section{Schnorr Protocol Rocq Encoding}
  We briefly explain the Schnorr protocol, an interactive protocol 
  between a prover and a verifier. 
  Given some public input $G = (g, q, h)$ where $G$
  is a cyclic group of prime order $q$, $g$ and $h$ are two 
  generators of the group $G$, the prover claims that they know a
  witness $w$ for the statement $h = g^w$; the existence of such
  a $w$ is immediate because $g$ generates the group. However,
  does the prover know the witness $w$? In order to convince the
  verifier, the prover and the verifier do the following:
  \begin{itemize}
    \item the prover picks a random number $u$, computes $a = g^u$,
    and sends $a$ to the verifier.
    \item the verifier picks a random challenge $c$ and sends it to
    the prover
    \item the prover computes $r = u + c * w$ and sends $r$ to the
    verifier
  \end{itemize}

The verifier accepts the transcript $(a, c, r)$ if $g^r = a * h^c$, otherwise rejects. We can prove that 
this protocol has completeness, special soundness, and special honest-verifier 
zero-knowledge proof. 


\begin{itemize}
  \item \textbf{completeness:} when $P$ and $V$ both follows the protocol, $V$ accepts the proof, i.e., 
  the verification equation checks out. We can see by algebraic simplification that it is the case.
    \begin{align*}
      g^r = g^{u + c * w} = g^u * (g^w)^c = a * h^c
    \end{align*}
  \item \textbf{special soundness:} from two accepting 
  conversations $(a, c, r)$ and $(a, c', r')$ where $c \neq c'$,
  a polynomial-time extractor can extract a witness $w$, 
  which is equal to $(r - r') * (c - c')^{-1}$, 
  such that $g^w = h$. By means of algebraic simplification, 
  we can see that it is the case.  
  \begin{align}
    g^r = a * h^c = g^u * (g^w)^c = g^{u + w * c}  \\
    g^{r'} = a * h^{c'} = g^u * (g^w)^{c'} = g^{u + w * c'}
  \end{align}
  Diving the expression (1) with (2), we get
  \begin{align*}
    g^{(r-r')} = g^{w * (c - c')}
  \end{align*}
  and multiplying both sides by $(c - c')^{-1}$ we 
  get 
  \begin{align*}
    g^{(r-r') * (c - c')^{-1}} = g^{w}
  \end{align*}

  \item \textbf{special honest-verifier zero-knowledge proof:}
   for a \emph{fixed} verifier challenge $c$, the distribution of transcripts from an honest
   conversation --involving witness $w$-- and the distribution of transcripts output by a
   simulator --without witness $w$-- are identical. We can see this algebraically: both
   distributions \ref{f} and \ref{snd} are uniform over $Z_q$, i.e., each transcript occurs
   with probability $1/q$.
   \begin{align}\label{f}
    \{(a, c, r) \mid u \in_{R} Z_q ; a := g^u; r := u + c * w \}
   \end{align}
   \begin{align}\label{snd}
    \{(a, c, r) \mid r \in_{R} Z_q ; a := g^r * h^{-c}\}
   \end{align}
   
\end{itemize}


In the Schnorr protocol, the elements $g$, $h$, and $a$ are group elements from the underlying group, while $u$, $c$, and $r$ are scalar values from the underlying prime field. In practice, both the group elements and the field elements are large 
numbers modulo some prime numbers, although the operations on them differ. 
One possibility is to encode the Rocq functions to work with concrete numbers from the underlying group and field, but this leads to cumbersome proofs because we need to deal with the details of concrete numbers during the security proofs. More importantly, it is not modular because it binds the formalisation to multiplicative groups; therefore, it can no longer be used over elliptic curve groups. For most programming languages, this distinction 
may not be significant, but it can be a potential source of bugs \cite{10.1007/978-3-662-63958-0_24} undermining the security of underlying cryptographic primitives. 
However, when encoding it in Rocq, we need to thoroughly detail these distinctions because 
the same large number can belong to a group or field and that dictates what operations are available for them. 
Therefore, to avoid this unpleasant situation,  
we abstract the underlying group as an abstract type $G$, endowed with 
usual group operation, and the underlying field as an abstract type $F$, endowed with 
field operation in our formalisation. 
Moreover, we abstract these two types into a vector space for smooth interaction between 
group element and field element (exponentiation in multiplicative group or mulitplication of a field element 
with a curve point in ellptic curve group is an instance of this interaction). This 
makes our formalisation generic that can be instantiated with 
any kind of group and field as long as it follows the axioms of 
vector space. For example, in our formalisation we have developed 
efficient algorithm for the Schnorr (mulitplicative) group but our formalisation can 
later be also instantiated with elliptic curve group. However, 
one of the major benefit of this abstraction is easiness of proofs 
which can be easily automated. Therefore, we model the Schnorr 
protocol, the simulator, and the verification equation in Rocq as follows: 
 
\begin{lstlisting}[frame=single, language=Coq, caption={Schnorr protocol},
  label={ind_nat},captionpos=t, basicstyle=\ttfamily\footnotesize,
  abovecaptionskip=-\medskipamount]
(*Real transcript (involves secret x)*)
Definition schnorr_protocol (x : F) (g : G) 
 (u c : F) : sigma_proto :=  
 ([g^u]; [c]; [u + c * x]).

(*Fake transcript (without the witness x)*)
Definition schnorr_simulator (g h : G) 
 (u c : F) : sigma_proto := 
 ([gop (g^u) (h^(opp c))]; [c]; [u]).

(*This function checks if a transcript (a; c; r) 
is accepting or not. It checks if g^r = a * h^c*)
Definition accepting_conversation (g h : G) 
 (v : sigma_proto) : bool :=
 match v with
 | (a; c; r) =>  
    match Gdec (g^r) (gop a (h^c)) with 
    | left _ => true
    | right _ => false 
    end
 end.
\end{lstlisting}
  
\noindent
 $F$ is the underlying field, $G$ is the underlying group,
 $+ : F \rightarrow F \rightarrow F$ is the field addition,
 $* : F \rightarrow F \rightarrow F$ is the field multiplication, 
 $gop : G \rightarrow G \rightarrow G$ is the group operation, and
 $\mbox{\textasciicircum}: G \rightarrow F \rightarrow G$ is the scalar multiplication of the underlying vector space.  
 Recall that a vector space consists of a set of 
 vectors, denoted by \(V\), a field \(F\) (elements of F are called scalars), and 
 two operations: vector addition and scalar multiplication.
\begin{itemize}
    \item \textit{Vector addition}: for any vectors \(\mathbf{v}, \mathbf{w} \in V\), their sum, denoted by \(\mathbf{v} + \mathbf{w}\), is also in \(V\).
    \item \textit{Scalar multiplication}: for any vector \(\mathbf{v} \in V\) and any scalar \(c \in F\), their product, denoted by \(c\mathbf{v}\), is also in \(V\).
\end{itemize}

These operations must satisfy the following properties for all vectors \(\mathbf{u}, \mathbf{v}, \mathbf{w} \in V\) and all scalars \(c, d \in F\):
(i) \textbf{closure under addition:} \(\mathbf{u} + \mathbf{v} \in V\), (ii) \textbf{commutativity of addition:} \(\mathbf{u} + \mathbf{v} = \mathbf{v} + \mathbf{u}\), 
(iii)  \textbf{associativity of addition:} \((\mathbf{u} + \mathbf{v}) + \mathbf{w} = \mathbf{u} + (\mathbf{v} + \mathbf{w})\), 
(iv) \textbf{existence of zero vector:} there exists a vector \(\mathbf{0} \in V\) such that \(\mathbf{v} + \mathbf{0} = \mathbf{v}\) for all \(\mathbf{v} \in V\), 
(v) \textbf{existence of additive inverse:} for each vector \(\mathbf{v} \in V\), there exists a vector \(-\mathbf{v} \in V\) such that \(\mathbf{v} + (-\mathbf{v}) = \mathbf{0}\),
(vi) \textbf{closure under scalar multiplication:} \(c\mathbf{v} \in V\), 
(vii) \textbf{cistributive properties:} \(c(\mathbf{u} + \mathbf{v}) = c\mathbf{u} + c\mathbf{v}\) and \((c + d)\mathbf{v} = c\mathbf{v} + d\mathbf{v}\), 
and (viii) \textbf{compatibility with field multiplication:} \(c(d\mathbf{v}) = (cd)\mathbf{v}\) and \(1\mathbf{v} = \mathbf{v}\), where \(1\) denotes the multiplicative identity in \(F\).
In our setting we instantiate the set of vectors with $G$ and field with $F$. 
Moreover, our notation for scalar multiplication is $\mbox{\textasciicircum}$ because it represents, 
when instantiated concretely, exponentiation function but it is purely for notational convenience. 


We prove the completeness and special soundness property of the Schnorr protocol, 
as shown in Listing \ref{comp_sound}. However, to prove the special honest-verifier 
zero-knowledge property we need a model to reason about uniform probability 
distribution in Rocq. The next section introduces this uniform  probability 
distribution model and its role in the special honest-verifier zero-knowledge proof. 

\begin{lstlisting}[frame=single, language=Coq, caption={Completeness and Soundness},
  label={comp_sound},captionpos=t, basicstyle=\ttfamily\footnotesize,
  abovecaptionskip=-\medskipamount]
Lemma schnorr_completeness : 
forall (r c : F) (a : t G 1) (c r : t F 1),
(a; c; r) = (schnorr_protocol x g r c) ->
accepting_conversation g h (a; c; r) = true.
Proof. (* proof terms omitted *) Qed.
  
Lemma simulator_completeness : 
forall (r c : F) (a : t G 1) (c r : t F 1),
(a; c; r) = (schnorr_simulator g h r c) ->
accepting_conversation g h (a; c; r) = true.
Proof using -(x R). (* terms omitted *) Qed. 
  
Lemma special_soundness: 
forall (a : G) (ca ra cb rb : F), ca <> cb ->
accepting_conversation g h ([a]; [ca]; [ra]) ->  
accepting_conversation g h ([a]; [cb]; [rb]) ->
exists y : F, g^y = h /\ y = ((ra - rb) * inv (ca - cb)).
Proof using -(x R). (* proof terms omitted *) Qed.
  
\end{lstlisting}
 
\subsection{Uniform Distribution}
To reason about special honest-verifier zero-knowledge proof 
intuitively, we need a model of uniform distribution. 
We follow \cite{erwig2006functional}  and 
encode the distribution a list of tuples where the 
second element of a tuple is probability --represented as 
a rational number-- of the first element 
of the tuple. Moreover, we define equality on distribution by 
stating that two distributions are equal if they are permutation 
of each other. This encoding is flexible and allows us 
to encode any kind of distribution. We prove that the dist is a 
monad \cite{erwig2006functional} by 
giving it a suitable definitions of \textit{ret} and 
\textit{bind}. Making it an instance of monad allows us 
to compose a distribution $d$ $n$ times to 
obtain a distribution on a vector of $n$ elements, 
needed in proving the special honest-verifier 
zero-knowledge proof of $n$ composed $\Sigma$-protocol.
However, we need uniform 
distribution, rather than an arbitrary distribution, to reason about 
zero-knowledge of $\Sigma$-protocol, and therefore we define a function, $uniform\_with\_replacement$, 
to generate uniform distributions, shown in Listing \ref{prob_def}.

\begin{lstlisting}[frame=single, language=Coq, caption={Definition of Uniform Probability Distribution},
    label={prob_def},captionpos=t, basicstyle=\ttfamily\footnotesize,
    abovecaptionskip=-\medskipamount]
(* Probability Distribution on a type A *)
Definition dist (A : Type) : Type := 
 list (A * prob).
  
(* Probability Monad *)
Definition Ret {A : Type} (x : A) : 
  dist A := [(x, one)].

Fixpoint Bind {A B : Type} (xs : dist A)  
  (f : A -> dist B) : dist B := 
  match xs with 
  | [] => [] 
  | (ax, px) :: tx => 
    List.append (List.map (fun '(ut, pt) => 
    (ut, mul_prob px pt)) (f ax)) (Bind tx f)
  end.

(* Uniform distribution *)
Definition uniform_with_replacement {A : Type} : 
  forall (l : list A), l <> [] -> dist A.
Proof.
  intros ? H.
  remember (Pos.of_nat (List.length l)) as len.
  exact (List.map 
    (fun x => (x, mk_prob 1 len)) l).
Defined.
\end{lstlisting}

  
We now have all ingredients for the special honest-verifier zero-knowledge proof of the Schnorr protocol. We define the 
Schnorr distribution $schnorr\_distribution$
that involves the secret $x$ and 
the simulator distribution $simulator\_distribution$
that does not involve the secret $x$, shown in Listing \ref{def_zero}. 
Both distributions sample a random field element $u$ from $uniform\_with\_replacement \text{ }lf \text{ } Hlfn$, where $lf$ lists the elements from which $u$ is drawn and $Hlfn$ asserts that $lf$ is non-empty, to construct their respective distributions on the sigma protocol. 
Using these definitions, we prove $special\_honest\_verifier\_zkp$: the two distributions coincide. Unlike the usual informal presentation, the distributions are over transcript--probability pairs $(a, c, r)$; they are accepting but not syntactically identical. We therefore apply $\mathit{accepting\_conversation}$ to the transcript component of each pair, which yields a boolean (true) in both cases. After this mapping, the distributions are identical, as required.


\begin{lstlisting}[frame=single, language=Coq, caption={Special Honest-Verifier Zero-Knowledge Proof},
  label={def_zero},captionpos=t, basicstyle=\ttfamily\footnotesize,
  abovecaptionskip=-\medskipamount]
(* Distribution that involves the secret x *)
Definition schnorr_distribution  (lf : list F) 
  (Hlfn : lf <> List.nil) (x : F) (g : G) (c : F) : 
  dist sigma_proto :=
  (* draw u from a random distribution *)
  u <- (uniform_with_replacement lf Hlfn) ;;
  Ret (schnorr_protocol x g u c).

(* without secret x *)
Definition simulator_distribution (lf : list F) 
  (Hlfn : lf <> List.nil) (g h : G) (c : F) : 
  dist sigma_proto :=
  (* draw u from a random distribution *)
  u <- (uniform_with_replacement lf Hlfn) ;;
  Ret (schnorr_simulator g h u c).
  
Lemma special_honest_verifier_zkp : 
  forall (lf : list F) (Hlfn : lf <> List.nil) (c : F), 
  List.map (fun '(a, p) => 
    (accepting_conversation g h a, p))
    (@schnorr_distribution lf Hlfn x g c) = 
  List.map (fun '(a, p) => 
    (accepting_conversation g h a, p))
    (@simulator_distribution lf Hlfn g h c).
Proof. (* proof terms omitted *) Qed. 
\end{lstlisting}

We have also formalised methods for combining $n$ \textit{And}, \textit{Or}, \textit{Eq}, \textit{Parallel}, and \textit{Neq} Schnorr statements, where proving the special honest-verifier zero-knowledge property is more challenging than for a single Schnorr statement. One major challenge is drawing $n$ random elements from a uniform distribution. To address this, we define the function $\mathtt{repeat\_dist\_ntimes\_vector}$---shown in Listing~\ref{dist_comp}---which takes a distribution $d$ and a number $n$ and returns a distribution over vectors of length $n$, encoded as $\mathsf{dist}\,(\mathsf{Vector.t}\,A\,n)$. Note that this is a generic function that can be instantiated with any distribution. In cryptography, however, we are primarily concerned with the uniform distribution; in the theorem $\mathtt{uniform\_probability\_multidraw\_prob}$, we instantiate the distribution with the uniform distribution $(\mathtt{uniform\_with\_replacement}\;lf\;Hlf)$ and prove that its probability is $1/|lf|^n$. We use this in the Parallel composition, where we combine $n$ statements and require a vector of $n$ random field elements to prove the zero-knowledge property, as demonstrated in $\mathtt{parallel\_schnorr\_distribution}$.


\begin{lstlisting}[frame=single, language=Coq, caption={Composition of a Distribution},
label={dist_comp},captionpos=t, basicstyle=\ttfamily\footnotesize,
abovecaptionskip=-\medskipamount]
Fixpoint repeat_dist_ntimes_vector {A : Type} 
(d : dist A) (n : nat) : dist (Vector.t A n) := 
match n with 
| 0 => Ret (@Vector.nil A)
| S n' => 
  Bind d (fun u => 
    Bind (repeat_dist_ntimes_vector d n')
    (fun v => Ret (Vector.cons _ u _ v)))
end.

Lemma uniform_probability_multidraw_prob 
{A : Type} : forall n (lf : dist A) 
(a : Vector.t A n) b (Hlf : lf <> []), 
In (a, b) (repeat_dist_ntimes_vector 
  (uniform_with_replacement lf Hlf) n) ->
b = mk_prob 1 (Nat.pow (List.length lf) n).
Proof. (* terms omitted *) Qed.

Definition parallel_schnorr_distribution  
  {n : nat} (lf : list F) (Hlfn : lf <> List.nil) 
  (x : F) (g : G) (cs : Vector.t F n) : 
  dist (@sigma_proto n n n) :=
  (* draw n random elements *)
  us <- repeat_dist_ntimes_vector 
    (uniform_with_replacement lf Hlfn) n ;;
  Ret (construct_parallel_schnorr x g us cs).
\end{lstlisting}


\subsection{OR Composition}
The Or-$\Sigma$ protocol allows a prover to demonstrate knowledge of one witness among $n$ possible discrete logarithm statements 
without revealing which specific statement they know. Formally, given public group elements $(g_1, h_1), (g_2, h_2), \ldots, (g_n, h_n)$, 
the prover convinces the verifier that they know a witness $x_k$ such that $h_k = g_k^{x_k}$ for some $k \in \{1, \ldots, n\}$, 
without revealing the index $k$ or the witness $x_k$. This construction is essential for privacy-preserving applications 
where a prover needs to demonstrate membership in a set while preserving anonymity.

The key insight behind the Or composition, introduced by Cramer, Damg\aa rd, and Schoenmakers~\cite{cramer1994proofs}, 
is to allow the prover a controlled degree of freedom to ``cheat'' on statements for which they do not know witnesses. 
The verifier provides a single challenge $c$, which the prover can split into $n$ sub-challenges 
$c_1, c_2, \ldots, c_n$ satisfying the linear constraint $c = \sum_{i=1}^{n} c_i$. 
For the statement where the prover knows the witness (say, statement $k$), they perform an honest Schnorr protocol. 
For all other statements $i \neq k$, the prover uses the simulator to generate fake transcripts by choosing 
random challenges $c_i$ and responses $s_i$ in advance, then computing the corresponding commitments as 
$t_i = g_i^{s_i} \cdot h_i^{-c_i}$. The prover sets $c_k = c - \sum_{i \neq k} c_i$ to satisfy the constraint, 
ensuring that the verifier's check passes while maintaining zero-knowledge.

Our formalisation implements this protocol generically for $n \geq 2$ statements. The prover, knowing the witness for the $k$-th relation (where $k$ is specified as a finite index of sort $\mathtt{Fin.t \text{ }(2+n)}$), first enters the commitment phase by choosing random values: $u_k$ for the real commitment, and for each simulated statement $i \neq k$, random values $u_i$ and $c_i$. The prover then computes the real commitment $t_k = g_k^{u_k}$ for statement $k$ and simulated commitments $t_i = g_i^{u_i} \cdot h_i^{-c_i}$ for $i \neq k$, sending the vector of commitments $(t_1, \ldots, t_n)$ to the verifier. In the challenge phase, the verifier responds with a random challenge $c$. Finally, during the response phase, the prover computes $c_k = c - \sum_{i \neq k} c_i$ to satisfy the linear constraint, along with $s_k = u_k + c_k \cdot x_k$ as the honest response for the real statement, while for $i \neq k$, the responses $s_i$ are set to the previously chosen $u_i$. The prover then sends both response vectors $(s_1, \ldots, s_n)$ and $(c_1, \ldots, c_n)$. The verifier accepts if: (i) $c = \sum_{i=1}^{n} c_i$, and (ii) for each $i$, $g_i^{s_i} = t_i \cdot h_i^{c_i}$.

Our Rocq formalisation of the Or-$\Sigma$ protocol, implemented in \texttt{OrSigmaGen.v}, supports $n \geq 2$ statements with arbitrary generators for each statement, enabling proofs of knowledge for relations $g_i^{x_i} = h_i$. The formalisation proves three security properties: completeness (honest execution always verifies), special soundness (shown in \texttt{generalised\_or\_sigma\_soundness\_main}, which recovers a witness from two accepting transcripts with the same commitments but different challenges), and special honest-verifier zero-knowledge (the distribution of real transcripts involving the witness is identical to the simulator distribution without the witness).

\begin{lstlisting}[frame=single, language=Coq, caption={Special Soundness},
label={dist_comp},captionpos=t, basicstyle=\ttfamily\footnotesize,
abovecaptionskip=-\medskipamount]
Lemma generalised_or_sigma_soundness_main
  {n : nat} (gs hs : Vector.t G (2 + n)): forall (a : Vector.t G (2 + n)) 
  (c1 c2 : F) (cs1 cs2 r1 r2 : Vector.t F (2 + n)),
  generalised_or_accepting_conversations 
    gs hs (a; c1 :: cs1; r1) = true ->
  generalised_or_accepting_conversations 
    gs hs (a; c2 :: cs2; r2) = true ->
  c1 <> c2 -> 
  (* There is an index where relation R is true and can 
    extract a witness out of it *)
  exists (f : Fin.t (2 + n)) (y : F),
  (nth gs f)^y = (nth hs f).
Proof. (* proof terms omitted *) Qed.
\end{lstlisting}

\subsection{Okamoto Protocol}

The Okamoto protocol~\cite{okamoto1992provably} generalises the Schnorr protocol to support multiple generators, thereby enabling proofs of knowledge for linear relations over discrete logarithms. While the Schnorr protocol proves 
knowledge of a single discrete logarithm $x$ such that $h = g^x$, the Okamoto protocol proves knowledge of 
multiple exponents $x_1, x_2, \ldots, x_n$ satisfying a relation $h = g_1^{x_1} \cdot g_2^{x_2} \cdots g_n^{x_n}$, 
where $g_1, g_2, \ldots, g_n$ are public generators and $h$ is a public group element. This construction is 
fundamental for building more complex protocols, particularly serving as a crucial sub-protocol in our 
inequality (Neq) composition where we need to prove distinctness of discrete logarithms.

The Okamoto protocol follows the standard three-move $\Sigma$-protocol structure. Given public generators $\mathbf{g} = (g_1, g_2, \ldots, g_n)$, a public value $h$, and secret witnesses $\mathbf{x} = (x_1, x_2, \ldots, x_n)$ satisfying $h = \prod_{i=1}^{n} g_i^{x_i}$, the prover begins by selecting random values $\mathbf{u} = (u_1, u_2, \ldots, u_n)$ from the underlying field and computing the commitment $t = \prod_{i=1}^{n} g_i^{u_i}$, which is sent to the verifier. Next, the verifier responds with a random challenge $c$ from the field. Finally, the prover computes responses $r_i = u_i + c \cdot x_i$ for each $i \in {1, \ldots, n}$ and sends the vector $\mathbf{r} = (r_1, r_2, \ldots, r_n)$ to the verifier for verification.

The verifier accepts the transcript $(t, c, \mathbf{r})$ if and only if 
$\prod_{i=1}^{n} g_i^{r_i} = t \cdot h^c$. Verification correctness follows from the fact that:
\[
\prod_{i=1}^{n} g_i^{r_i} = \prod_{i=1}^{n} g_i^{u_i + c \cdot x_i} = 
\left(\prod_{i=1}^{n} g_i^{u_i}\right) \cdot \left(\prod_{i=1}^{n} g_i^{x_i}\right)^c = t \cdot h^c
\]

Our Rocq formalisation implements the generalised Okamoto protocol for $n \geq 2$ generators in 
Okamoto.v. The key functions include: 
\texttt{generalised\_okamoto\_commitment} (computes $\prod_{i=1}^{n} g_i^{u_i}$ by folding 
scalar multiplication over the generator-randomness pairs), 
\texttt{generalised\_okamoto\_response} (computes the vector of responses $r_i = u_i + c \cdot x_i$ 
using component-wise operations), and 
\texttt{generalised\_okamoto\_accepting\_conversation} (verifies the product equality condition). 
We also provide specialised instances for the base case of exactly two generators ($n=2$), which is heavily used in the Neq composition.

The formalisation proves all three security properties:
\begin{itemize}
\item \textbf{Completeness}: 
When both prover and verifier follow the protocol honestly with $h = \prod_{i=1}^{n} g_i^{x_i}$, 
the verification check always succeeds. The proof proceeds by induction on $n$, leveraging the 
vector space properties of scalar multiplication distributivity over field addition.

\item \textbf{Special soundness}: 
Given two accepting transcripts $(t, c_1, \mathbf{r}_1)$ and $(t, c_2, \mathbf{r}_2)$ with 
the same commitment $t$ but different challenges $c_1 \neq c_2$, an extractor can compute 
witnesses $\mathbf{x} = (x_1, \ldots, x_n)$ where 
$x_i = (r_{1,i} - r_{2,i}) \cdot (c_1 - c_2)^{-1}$ for each $i$. The proof establishes that 
these extracted values satisfy $h = \prod_{i=1}^{n} g_i^{x_i}$, which is critical for the 
soundness of the Neq protocol that uses Okamoto as a building block.

\item \textbf{Special honest-verifier zero-knowledge}: 
The real transcript distribution (involving secrets $\mathbf{x}$) is identical to the simulator 
distribution (without secrets). The simulator chooses random $\mathbf{u}$ and $c$, then computes 
the commitment as $t = \left(\prod_{i=1}^{n} g_i^{u_i}\right) \cdot h^{-c}$ with responses 
$\mathbf{r} = \mathbf{u}$. Both distributions produce accepting transcripts with probability 
$1/|\mathbb{F}|^n$ where $\mathbb{F}$ is the underlying field, proven using our uniform probability 
distribution framework.
\end{itemize}

Beyond the standard $\Sigma$-protocol properties, our formalisation includes witness indistinguishability 
results critical for the Neq composition. We prove that transcripts generated with different witness 
vectors $\mathbf{x}_1$ and $\mathbf{x}_2$ satisfying the same relation $h = \prod_{i=1}^{n} g_i^{x_1,i} = 
\prod_{i=1}^{n} g_i^{x_2,i}$ are computationally indistinguishable. This is established through the 
bijective transformation functions \texttt{transform\_us} and \texttt{inverse\_transform} that map 
randomness between the two witness spaces, along with the homomorphic property showing that 
$\prod_{i=1}^{n} g_i^{u_i - v_i} = \left(\prod_{i=1}^{n} g_i^{u_i}\right) \cdot 
\left(\prod_{i=1}^{n} g_i^{-v_i}\right)$.

\begin{lstlisting}[frame=single, language=Coq, caption={Witness Indistinguishability},
label={dist_comp},captionpos=t, basicstyle=\ttfamily\footnotesize,
abovecaptionskip=-\medskipamount]
(* WI *)
Definition transform_us {n : nat} (xs1 xs2 : Vector.t F (2 + n)) 
  (c : F) (us : Vector.t F (2 + n)) : Vector.t F (2 + n) :=
  zip_with (fun u '(x1, x2) => u + c * (x1 - x2)) us 
  (zip_with pair xs1 xs2).


Definition inverse_transform {n : nat} (xs1 xs2 : Vector.t F (2 + n)) 
  (c : F) (us : Vector.t F (2 + n)) : Vector.t F (2 + n) :=
  zip_with (fun u '(x1, x2) => u + c * (x2 - x1)) us 
  (zip_with pair xs1 xs2).

Theorem generalised_okamoto_witness_indistinguishable {n : nat} :
  forall (gs : Vector.t G (2 + n)) (h : G) (xs1 xs1 : Vector.t F (2 + n)),
  (* Both witnesses produce the same public key h *)
  h = generalised_okamoto_commitment gs xs1 ->
  h = generalised_okamoto_commitment gs xs2 ->
  (* For every conversation (a, c, rs) from xs, there exists unique us' 
    such that the same conversation is produced by xs' *)
  forall (us rs : Vector.t F (2 + n)) (a : G) (c : F),
  ([a]; [c]; rs) = generalised_okamoto_real_protocol xs1 gs h us c ->
  (* Then there exists unique us' producing the same transcript for xs' *)
  exists! us' : Vector.t F (2 + n),
    ([a]; [c]; rs) = generalised_okamoto_real_protocol xs2 gs h us' c.
Proof. (* proof terms omitted *) Qed.
\end{lstlisting}

\subsection{Neq Composition}

The Neq (inequality) $\Sigma$-protocol enables a prover to demonstrate that they know distinct discrete 
logarithms for multiple public keys with respect to a common generator. Formally, given a generator $g$ 
and public values $h_1, h_2, \ldots, h_n$, the prover proves knowledge of secrets 
$x_1, x_2, \ldots, x_n$ such that (i) $g^{x_i} = h_i$ for all $i \in \{1, \ldots, n\}$, and 
(ii) $x_i \neq x_j$ for all distinct pairs $i \neq j$. This protocol is essential in voting systems 
for proving ballot validity constraints beyond simple well-formedness, though it is less commonly 
deployed than Or and And compositions in current systems like Helios and Belenios.

Unlike the Or and And compositions which prove logical connectives over basic Schnorr statements, 
the Neq composition addresses a fundamentally different problem: proving pairwise inequality 
constraints among witnesses. The challenge lies in ensuring that the prover cannot reuse the same 
discrete logarithm for multiple public keys while maintaining zero-knowledge. Our construction 
achieves this by combining two sub-protocols: an And composition that establishes knowledge of all 
discrete logarithms, and multiple Okamoto protocols that enforce the pairwise inequality constraints.

The protocol structure for $n \geq 2$ statements is inherently quadratic in complexity due to 
the pairwise nature of inequality constraints. For each pair of indices $(i, j)$ with $i < j$, 
the prover must demonstrate that $x_i \neq x_j$ without revealing the values. Our implementation 
in NeqSigma.v works as follows: the protocol begins with the commitment phase, in which the prover generates randomness for two components. For the And component, the prover uses $n$ random values to create commitments $t_i = g^{u_i}$ for each $i \in {1, \ldots, n}$, proving knowledge of all discrete logarithms. For the Okamoto component, the prover generates an Okamoto commitment for each pair $(i, j)$ with $i < j$ using generators $(g \cdot h_i, h_j)$ and specially constructed witnesses $\left(x_i \cdot (x_i - x_j)^{-1}, (x_j - x_i)^{-1}\right)$ that encode the inequality constraint, resulting in $\binom{n}{2} = n(n-1)/2$ such commitments. The combined commitment vector, of dimension $n + \binom{n}{2}$, is then sent to the verifier. In the challenge phase, the verifier responds with a random challenge $c$ from the underlying field. Finally, in the response phase, the prover computes two sets of responses: the And responses $r_i = u_i + c \cdot x_i$ for each $i$ (as in the standard And composition), and the Okamoto responsesa two-dimensional response for each pair $(i, j)$ using the transformed witnesses and randomness, yielding $n(n-1)$ field elements in total. This results in a response vector of dimension $n + n(n-1) = n^2$, which is sent to the verifier.


The verifier accepts if both sub-protocol verifications succeed: (i) the And verifier confirms that 
each $g^{r_i} = t_i \cdot h_i^c$, and (ii) for each pair $(i, j)$, the Okamoto verifier confirms that 
the relation $(g \cdot h_i)^{r_{i,1}} \cdot h_j^{r_{i,2}} = t_{i,j} \cdot (g \cdot h_i)^c$ holds, 
where $r_{i,1}, r_{i,2}$ are the two responses for pair $(i,j)$ and $t_{i,j}$ is the corresponding 
Okamoto commitment. The correctness of the Okamoto component for inequality relies on the algebraic identity: if $x_i = x_j$, 
then $(x_i - x_j)^{-1}$ would be undefined (division by zero), making it impossible for the prover to 
construct valid witnesses. Conversely, when $x_i \neq x_j$, the witnesses 
$\left(x_i \cdot (x_i - x_j)^{-1}, (x_j - x_i)^{-1}\right)$ satisfy $(g \cdot h_i)^{x_i \cdot (x_i - x_j)^{-1}} \cdot h_j^{(x_j - x_i)^{-1}}$ = $g^{x_i \cdot (x_i - x_j)^{-1}} \cdot h_i^{x_i \cdot (x_i - x_j)^{-1}} \cdot h_j^{(x_j - x_i)^{-1}}$ = $g$ after algebraic simplification using $h_i = g^{x_i}$ and $h_j = g^{x_j}$.

Our Rocq formalisation proves the three standard $\Sigma$-protocol properties:

\begin{itemize}
\item \textbf{Completeness}: 
When the prover knows distinct witnesses $x_1, \ldots, x_n$ satisfying $g^{x_i} = h_i$ and $x_i \neq x_j$ 
for all $i \neq j$, the verification always succeeds. The proof combines completeness results from both the And composition completenes and the Okamoto protocol completeness for each pair.

\item \textbf{Special soundness}: 
From two accepting transcripts with the same commitments but different challenges $c_1 \neq c_2$, 
an extractor can recover witnesses $x_1, \ldots, x_n$ satisfying the discrete logarithm relations. 
However, proving that the extracted witnesses are necessarily distinct requires an additional assumption about generator independence. Our formalisation proves an unconditional dichotomy: either the extracted witnesses are pairwise distinct, \emph{or} there exists a non-trivial discrete logarithm relation between generators (e.g., $g_j = g_i^\alpha$ for some $\alpha$, or one generator is the identity). This captures special soundness without assuming independence explicitly, leveraging decidability of the relevant propositions to convert the implication into a constructive disjunction.

\item \textbf{Special honest-verifier zero-knowledge}: 
The real transcript distribution (generated with witnesses $x_1, \ldots, x_n$) is identical to the 
simulator distribution (without witnesses). The simulator splits randomness between And and Okamoto 
components: for And, it uses the standard simulator producing commitments $t_i = g^{u_i} \cdot h_i^{-c}$; 
for each Okamoto pair, it generates simulated commitments independently. Both distributions produce 
accepting transcripts with probability $1/|\mathbb{F}|^{n + n(n-1)} = 1/|\mathbb{F}|^{n^2}$, proven 
using our uniform probability distribution framework.
\end{itemize}

The implementation requires randomness of dimension $n + n(n-1) = n^2$ and produces proof transcripts of size $O(n^2)$, which reflects the quadratic nature of pairwise inequality constraints.


\begin{lstlisting}[frame=single, language=Coq, caption={Witness Indistinguishability},
label={dist_comp},captionpos=t, basicstyle=\ttfamily\footnotesize,
abovecaptionskip=-\medskipamount]
Theorem generalised_neq_accepting_conversations_soundenss :
  forall (n : nat) (a : Vector.t G (2 + n + (2 + n) * (1 + n) / 2)) 
  (c1 c2 : F) (rs1 rs2 : Vector.t F (2 + n + (2 + n) * (1 + n))) 
  (gs hs : Vector.t G (2 + n)), [c1] <> [c2] ->
  generalised_neq_accepting_conversations gs hs (a; [c1]; rs1) = true ->
  generalised_neq_accepting_conversations gs hs (a; [c2]; rs2) = true ->
  exists (xs : Vector.t F (2 + n)), 
  (forall (i : Fin.t (2 + n)), hs[@i] = gs[@i] ^ xs[@i]) /\
  ((forall (i j : Fin.t (2 + n)), i <> j -> xs[@i] <> xs[@j]) \/
  (exists (i j : Fin.t (2 + n)), i <> j /\ 
  ((exists (alpha : F), gs[@j] = gs[@i] ^ alpha) \/ 
  gs[@i] = gid \/ gs[@j] = gid)))
\end{lstlisting}

\subsection{Linear Relation over Pedersen Commitment}

The Pedersen Linear Relation protocol is a zero-knowledge proof for proving knowledge of openings 
(secret values and randomness) of Pedersen commitments that satisfy a linear constraint. Unlike the 
protocols discussed so far which prove discrete logarithm relations directly, this protocol operates 
over Pedersen commitments~\cite{pedersen1991non}, which are computationally binding and 
information-theoretically hiding --commonly used in cryptographic constructions. Formally, given generators $g$ 
and $h$ (where the discrete logarithm of $h$ with respect to $g$ is unknown), public coefficients 
$\alpha_1, \alpha_2, \ldots, \alpha_n$, and public commitments $C_1, C_2, \ldots, C_n$, the prover 
proves knowledge of values $(v_1, r_1), (v_2, r_2), \ldots, (v_n, r_n)$ such that:
\begin{itemize}
\item $C_i = g^{v_i} \cdot h^{r_i}$ for all $i$ (each commitment opens correctly)
\item $z = \sum_{i=1}^{n} \alpha_i \cdot v_i$ (a linear constraint on the committed values)
\end{itemize}

This construction has important applications in advanced cryptographic protocols. For instance, in 
voting systems with decentralised tallying, election authorities may commit to their votes using 
Pedersen commitments and prove that the sum of their committed values equals the final tally without 
revealing individual votes. The unknown discrete log of $h$ ensures that revealing the randomness 
$r_i$ does not leak the corresponding committed value $v_i$.

The protocol follows the standard three-move $\Sigma$-protocol structure for $n$ commitments with a single linear constraint, requiring $2n$ fresh randomness values (denoted $u_1, \ldots, u_n$ and $w_1, \ldots, w_n$) and producing $(n+1)$ commitment group elements and $2n$ response field elements. In the commitment phase, the prover samples fresh randomness $u_1, \ldots, u_n, w_1, \ldots, w_n$ and computes for each $i \in {1, \ldots, n}$ the commitment $t_i = g^{u_i} \cdot h^{w_i}$, mimicking the structure of $C_i$, along with an additional commitment $t_{n+1} = g^{\sum_{i=1}^{n} \alpha_i \cdot u_i}$ to the linear combination of randomness. The prover then sends the commitment vector $(t_1, \ldots, t_n, t_{n+1})$ to the verifier. In the challenge phase, the verifier responds with a random field element $c$. During the response phase, the prover computes for each $i$ the responses $s_{1,i} = u_i + c \cdot v_i$ and $s_{2,i} = w_i + c \cdot r_i$, sending the two vectors $(s_{1,1}, \ldots, s_{1,n})$ and $(s_{2,1}, \ldots, s_{2,n})$. The verifier accepts the transcript if both verification equations hold: for all $i$, $g^{s_{1,i}} \cdot h^{s_{2,i}} = t_i \cdot C_i^c$ (verifying each Pedersen commitment), and $g^{\sum_{i=1}^{n} \alpha_i \cdot s_{1,i}} = t_{n+1} \cdot g^{c \cdot z}$ (verifying the linear constraint).

Verification correctness follows from the homomorphic properties of the commitment scheme: if the 
prover is honest with secrets $(v_i, r_i)$ satisfying $C_i = g^{v_i} \cdot h^{r_i}$ and 
$z = \sum_i \alpha_i \cdot v_i$, then:
\begin{align*}
g^{s_{1,i}} \cdot h^{s_{2,i}} &= g^{u_i + c \cdot v_i} \cdot h^{w_i + c \cdot r_i} = 
(g^{u_i} \cdot h^{w_i}) \cdot (g^{v_i} \cdot h^{r_i})^c = t_i \cdot C_i^c \\
g^{\sum_i \alpha_i \cdot s_{1,i}} &= g^{\sum_i \alpha_i \cdot (u_i + c \cdot v_i)} = 
g^{\sum_i \alpha_i \cdot u_i} \cdot g^{c \cdot \sum_i \alpha_i \cdot v_i} = t_{n+1} \cdot g^{c \cdot z}
\end{align*}

Our Rocq formalisation in PedLinearRel.v implements this protocol 
with generic support for arbitrary $n \geq 2$ commitments and linear constraints. The formalisation proves all three security properties:

\begin{itemize}
\item \textbf{Completeness}: 
When the prover knows values $(v_1, r_1), \ldots, (v_n, r_n)$ satisfying both $C_i = g^{v_i} \cdot h^{r_i}$ 
and $z = \sum_i \alpha_i \cdot v_i$, the protocol always verifies successfully.

\item \textbf{Special soundness}: 
From two accepting transcripts with the same commitments but different challenges $c_1 \neq c_2$, 
an extractor recovers the witness values: $v_i = (s_{1,i}^{(1)} - s_{1,i}^{(2)}) \cdot (c_1 - c_2)^{-1}$ 
and similarly for $r_i$. The extraction is guaranteed to produce valid commitments $C_i = g^{v_i} \cdot h^{r_i}$. 
For the linear constraint, the formalisation proves a dichotomy: either $z = \sum_i \alpha_i \cdot v_i$ holds, 
or the group element $g$ is the identity (which is a degenerate case). This unconditional result avoids 
assumptions on the problem structure.

\item \textbf{Special honest-verifier zero-knowledge}: 
The distribution of real transcripts (generated with honest witnesses) is identically equal to the 
simulator distribution (without witnesses). Both produce accepting transcripts with probability 
$1/|\mathbb{F}|^{2n}$, proven using our uniform distribution framework. The identical distributions 
guarantee information-theoretic security: the verifier learns nothing beyond the validity of the 
statements, even with unlimited computational power.
\end{itemize}

The protocol supports arbitrary linear constraints through the algebraic structures provided by the 
field and group abstractions, making it widely applicable to systems requiring commit-and-prove 
mechanisms over structured secrets.



\subsection{Efficient Modular Arithmetic}
As stated earlier, to ensure the ease of proving and modularity, 
we worked with an (abstract) vector space. However, to execute the code of 
our formalisation, we need to instantiate the vector space with a concrete entity. 
Therefore, we have encoded a prime field --shown in Listing \ref{field_def}-- 
and the Schnorr group \cite{schnorr1991efficient} (mulitplicative 
group of integers modulo a large prime p) --shown in Listing \ref{group_def}-- in the Coq theorem prover. 
To encode the Schnorr group, we postulate three integer $k, p, \text{ and } q$. 
Moreover, we assume $p \text{ and } q$ are primes where $p = k * q + 1$ (when 
$k = 2$, these primes are called Sophie Germain primes). Finally, 
we encode the neutral element ($one$), the group multiplication ($mul\_schnorr\_group$), 
and the group inverse $inv\_schnorr\_group$ and we prove that our encoding 
of the Schnorr group in Coq is commutative group by making it 
an instance of the typeclass $schnorr\_comm$, which is an abstract typeclass that bundles the axioms 
of commutative group. 





 \begin{lstlisting}[frame=single, language=Coq, caption={Coq Encoding of the Schnorr Group},
  label={group_def},captionpos=t, basicstyle=\ttfamily\footnotesize,
  abovecaptionskip=-\medskipamount]
Section SchnorrGroup. 
  Context 
    {k p q : Z} {Hk : p = k * q + 1}
    {Hp : prime p} {Hq : prime q}.

  Record Schnorr_group := mk_schnorr 
    {v : Z; Ha : 0 < v < p; 
    Hb : v ^ q mod p = 1}.

  (* u ^ (p - 2) is inverse of u *)
  Definition inv_schnorr_group 
  (u : Schnorr_group) : Schnorr_group.
  refine(
    match u with 
    | mk_schnorr au Hu Hv => mk_schnorr
        (* terms omitted *)
    end).
  Defined.

  (* Schnorr is a commutative Group *)
  Global Instance schnorr_comm : 
    @commutative_group 
    Schnorr_group (@eq Schnorr_group) 
    mul_schnorr_group one inv_schnorr_group.
  Proof. ... Qed. 
End SchnorrGroup.
\end{lstlisting}


In order to encode prime field, we postulate an integer $p$ and 
axiom that $p$ is prime. We encode the prime field as 
a record $Zp$ that contains an integer $v$ with an axiom 
that it is in the range of $[0 \ldots p)$. Moreover, 
we define all the operation of $Zp$ and prove that 
it is an instance of the typeclass $zp\_field$, which is 
a typeclass that encodes the axioms of a field. 

\begin{lstlisting}[frame=single, language=Coq, caption={Coq Encoding of Prime Field},
  label={field_def},captionpos=t, basicstyle=\ttfamily\footnotesize,
  abovecaptionskip=-\medskipamount]
(* Prime Field *)
Section ZpField.
  Context 
    {p : Z} {Hp : prime p}.

  Record Zp := mk_zp 
    {v : Z; Hv : Z.modulo v p = v}.

  Global Instance zp_field : @field Zp zero 
    one zp_opp zp_add zp_sub zp_mul zp_inv zp_div.
End ZpField. 
\end{lstlisting}

Finally, we combine the Schnorr group and the prime field 
into a vector space instantiating the vector set with 
the Schnorr group and the scalar set with the prime field, 
shown in Listing \ref{vec_space}. 
However, in order to establish that it is an 
instance of vector space we need the definition 
of scalar mulitiplication. We encode the  
the scalar mulitplication $pow$ of 
vector space that takes an element from 
a Schnorr group and an element from 
the prime field and returns an element in the 
Schnorr group.  The reader can see that our encoding eliminates all 
possibilities of mixing group and field, both represented 
as an integer modulo some large 
prime \cite{10.1007/978-3-662-63958-0_24}.

\begin{lstlisting}[frame=single, language=Coq, caption={Vector Space Instantiation},
  label={vec_space},captionpos=t, basicstyle=\ttfamily\footnotesize,
  abovecaptionskip=-\medskipamount]

  Definition pow (g : @Schnorr.Schnorr_group p q) 
  (y : @Zpfield.Zp q) : @Schnorr.Schnorr_group p q.
  refine 
    match g, y with 
    | mk_schnorr gt Hgta Hgtb, mk_zp yt Hyt => 
      mk_schnorr  (Npow_mod gt yt p) 
      (pow_subproof_first _ _ Hgta Hyt)
      (pow_subproof_second _ _ Hyt Hgta Hgtb)
    end.
  Defined.

  Global Instance pow_vspace : 
  @vector_space 
    (* Field *)
    (@Zpfield.Zp q) (@eq (@Zpfield.Zp q))
    (@Zpfield.zero q Hq) (@Zpfield.one q Hq)
    (@Zpfield.zp_add q) (@Zpfield.zp_mul q)
    (@Zpfield.zp_sub q) (@Zpfield.zp_div q)
    (@Zpfield.zp_opp q Hq) (@Zpfield.zp_inv q)
    (* Vector *)
    (Schnorr_group p q) (@eq (Schnorr_group p q))
    (@one p q Hp Hq) 
    (@inv_schnorr_group k p q Hk Hp Hq)
    (@Schnorr.mul_schnorr_group p q Hp Hq)
    pow.
  
\end{lstlisting}

\subsection{Efficient Extractor.}
In this section we explain the ideas behind the formalisation of 
efficient extractor and simulator. Recall that in $\Sigma$-protocol, 
the extractor is efficient, i.e., it runs in polynomial time in its input length.
However, the functions from the vector space does not captures the 
infomation about complexity of operations, i.e., they do not 
capture the number of steps they take to compute for a given input. 
In our formalisation, we found that we could have followed the 
monadic approach \cite{10.1145/3473585,10.1145/3158124} by adding an extra 
return value for the number of steps it takes during the 
execution for a given input for all the functions in vector space. 
Moreover, monadic approach composes well, i.e., we can take 
two monadic functions and by composing them together we 
can compute the complexity of composed function. However, 
during the code extraction into Rust and WebAssembly, it would 
have stuck with all the function and destroyed our APIs. 
Therefore, we decided to take another approach. 
In practice, an extractor in multiplicative group is 
a function that can compute the inverse efficiently and 
in our concrete model we compute inverse using 
the binary exponentiation function $repeat\_op\_ntimes\_rec$. 
Therefore, we decided to encode an inductive data type $complexity\_repeat\_op\_ntimes\_rec$ --shown in \ref{extractor_complex}--
that captures the number of steps of a binary exponentiation 
fuction. Finally, we proved in theorem $correct\_complexity\_repeat\_op\_ntimes\_rec$ that 
(concrete) function $repeat\_op\_ntimes\_rec$ runs in logarithmic in its input, or 
polynomial (linear) in the nubmer of bits of its input. With this method, 
we do not need to change anything in our API but the downside is that 
it does not compose well like monadic approach. Nonetheless, it is 
sufficient for our approach because our main goal is to extract 
Rust and WebAssembly from our formalisation whose API are closely 
aligned with a real-world library. 


\begin{lstlisting}[frame=single, language=Coq, caption={Extractor Complexity},
  label={extractor_complex},captionpos=t, basicstyle=\ttfamily\footnotesize,
  abovecaptionskip=-\medskipamount]
Inductive complexity_repeat_op_ntimes_rec 
(e t : N) : positive -> N -> N -> Prop :=
| xH_case : complexity_repeat_op_ntimes_rec e t xH 
    (N.modulo e t) N0
| xO_case p ret w : 
    complexity_repeat_op_ntimes_rec e t p ret w ->
    complexity_repeat_op_ntimes_rec e t (xO p) 
    (N.modulo (ret * ret) t) (N.succ w)
| xI_case p ret w : 
    complexity_repeat_op_ntimes_rec e t p ret w ->
    complexity_repeat_op_ntimes_rec e t (xI p) 
    (N.modulo (e * (ret * ret)) t) (N.succ w).

Lemma correct_complexity_repeat_op_ntimes_rec : 
  forall n e w, complexity_repeat_op_ntimes_rec 
    (repeat_op_ntimes_rec e n w)  (N.log2 n).
Proof. (* proof terms omitted *) Qed.
\end{lstlisting}

\section{Case Studies/Experiment}\label{case_studies}

\subsection{Approval Voting}

Approval voting is a voting method where each voter can approve any subset of candidates independently. 
Unlike plurality voting where each voter selects exactly one candidate, approval voting allows voters to express 
support for multiple candidates, resulting in fairer representation of voter preferences. Our formalisation 
implements approval voting using ElGamal encryption paired with \emph{Or-$\Sigma$} proofs to guarantee that 
each vote is either 0 (not approved) or 1 (approved). This prevents voters from casting invalid votes such 
as fractional approvals or voting multiple times for the same candidate.

\textbf{Vote Encryption and Proof Generation}: The voting phase is implemented in [Frontend/Approval.v](src/Frontend/Approval.v). 
For each candidate $i$ in an election with $n$ candidates, the voter generates a vote $m_i \in \{0, 1\}$ 
indicating approval ($m_i = 1$) or non-approval ($m_i = 0$). This vote is encrypted using ElGamal encryption 
as $C_i = (g^{r_i}, g^{m_i} \cdot h^{r_i})$ where $r_i$ is random randomness, $h = g^x$ is the election's 
public key, and $g$ is the Schnorr group generator.

To prove that each ciphertext correctly encrypts a 0 or 1 vote, the verifier generates a proof using the 
generalized Or-$\Sigma$ composition (\texttt{generalised\_construct\_encryption\_proof\_elgamal\_real}). 
The proof has two branches corresponding to the two possible vote values:
\begin{itemize}
\item \textbf{Branch 1}: Proves that the ciphertext encrypts 0 by demonstrating knowledge of the discrete 
logarithm relation between $g$ and $1$ using generators $[g^0, g^1] = [1, g]$.
\item \textbf{Branch 2}: Proves that the ciphertext encrypts a non-zero value by demonstrating knowledge 
of the discrete logarithm relation between $g$ and $g^{m_i}$ using generators $[g^0, g^{m_i}]$.
\end{itemize}
The verifier selects one branch as the ``real'' branch based on the actual vote value: if $m_i = 0$, 
the proof is constructed in Branch 1 using randomness $r_i$; if $m_i \neq 0$, the proof is constructed 
in Branch 2. The other branch is simulated using random challenges and responses, and the two branches 
are combined into a single challenge $c = c_1 \oplus c_2$ where the opening demonstrates knowledge 
corresponding to the real branch.

\textbf{Ballot Generation and Verification}: The function \texttt{encrypt\_ballot\_and\_generate\_enc\_proof} 
extends vote encryption to the entire ballot by vectorizing across all $n$ candidates. Each candidate 
produces a tuple $(C_i, \pi_i)$ where $C_i$ is the encrypted vote and $\pi_i$ is the corresponding Or-$\Sigma$ 
proof. A complete ballot is thus a vector of $n$ such tuples, which voters submit along with a commitment 
to their randomness (used for auditability).

The verification function \texttt{verify\_encryption\_ballot\_proof} checks all Or-$\Sigma$ proofs in the 
ballot using \texttt{generalised\_accepting\_encryption\_proof\_elgamal}, rejecting any ballot with a 
false proof. This ensures that election authorities cannot process invalid ballots.

\textbf{Homomorphic Tallying}: After verifying all ballots, election authorities tally the results 
using homomorphic aggregation, implemented in [Backend/Tally.v](src/Backend/Tally.v). The tallying 
process is formalized as a state machine with two phases:

\begin{itemize}
\item \textbf{Partial State}: Election authorities process incoming ballots sequentially. For each valid 
ballot with verified Or-$\Sigma$ proofs, the encrypted votes are aggregated using the homomorphic property 
of ElGamal encryption: $\prod_j C_{i,j} = (g^{\sum_j r_{i,j}}, g^{\sum_j m_{i,j}} \cdot h^{\sum_j r_{i,j}})$. 
This is computed incrementally by the function \texttt{mul\_encrypted\_ballots}, which multiplies ciphertexts 
component-wise. Invalid ballots (with false Or-$\Sigma$ proofs) are rejected and excluded from the tally. 
The system maintains an invariant that the set of processed ballots equals the concatenation of valid ballots 
plus rejected invalid ballots: $\text{Permutation}(\mathit{bs}, \mathit{vbs} \append \mathit{inbs})$.

\item \textbf{Finished State}: Once all ballots are processed, the final tally ciphertext for each candidate 
is $(g^{\sum_j r_j}, g^{\sum_j m_j} \cdot h^{\sum_j r_j})$. The election authorities decrypt this to recover 
$\sum_j m_j$, the total number of approvals for that candidate, by computing the discrete logarithm 
$\text{dlog}_g(g^{\sum_j m_j})$ using discrete logarithm search. Since vote values are restricted to 
$\{0, 1\}$ by Or-$\Sigma$ proofs, the discrete logarithm search is efficient: the result is bounded by 
the number of voters.
\end{itemize}

\textbf{Formal Verification}: The Or-$\Sigma$ proofs guarantee that every encrypted vote encrypts exactly 
0 or 1. Combined with homomorphic encryption, this ensures that the final tally ciphertext decrypts to 
$\sum_j m_j \in [0, n]$ where $n$ is the number of voters, preventing vote inflation, under-counting, 
and phantom ballots. Our formalisation proves completeness of Or-$\Sigma$ proofs and the correctness 
of homomorphic aggregation, confirming that the approval voting system is sound and complete.

\subsection{Helios Verifier}

To demonstrate the practical applicability of our formalisation, we have developed a certified verifier for 
the Helios voting system that processes real-world election data from the IACR elections. Helios is a 
widely-deployed open-source internet voting system that implements end-to-end verifiable elections using 
cryptographic proofs. Our verifier validates the complete election tally including ballot verification, 
ciphertext aggregation, and decryption verification using the formal proofs embedded in our Rocq formalisation.

\textbf{Architecture and Workflow}: The Helios verifier is implemented in OCaml and extracted from our 
Rocq specifications. It operates in two stages:

\begin{enumerate}
\item \textbf{Input Parsing}: The verifier reads election data in JSON format from stdin, parsing ballots, 
tallier decryption factors, and proofs using a custom parser (\texttt{Executable/HeliosVerifiercode/parsing/parser.mly}) 
and lexer (\texttt{parsing/lexer.mll}). The AST module translates JSON into OCaml data structures corresponding 
to Rocq ballot and tallier records.

\item \textbf{Verification Engine}: The core verification logic is defined in [Backend/HeliosTally.v](src/Backend/HeliosTally.v) 
and instantiated with concrete parameters in [Examples/HeliosTallyIns.v](src/Examples/HeliosTallyIns.v). 
The verifier implements a state machine with inductive rules corresponding to election phases.
\end{enumerate}

\textbf{Verification Rules}: The election verification process follows an operational semantics defined by 
the \texttt{count} inductive type in HeliosTally.v:

\begin{itemize}
\item \textbf{Initial state (ax)}: Begins with an empty ballot list and an identity-encrypted tally 
(ciphertext $(g^0 h^0, g^0 h^0) = (1, 1)$ in each position), representing zero votes before tallying begins.

\item \textbf{Valid ballot (cvalid)}: For each ballot, the verifier checks the encryption proof using the 
Or-$\Sigma$ composition with two disjunctions (proving encryption of 0 or 1 for approval voting). If the proof 
succeeds, the ballot's ciphertext is homomorphically aggregated into the running encrypted tally using 
the ElGamal multiplication operation. The ballot is marked as valid.

\item \textbf{Invalid ballot (cinvalid)}: If the encryption proof fails, the ballot is rejected and marked 
as invalid. The encrypted tally remains unchanged, preserving the invariant that only verified ballots 
contribute to the final count.

\item \textbf{Finalization (finish)}: After all ballots are processed, the verifier performs end-to-end 
verification checks:
\begin{enumerate}
\item Decryption verification: Each of the $m$ talliers has published a decryption factor $d_i = \alpha^{s_i}$ 
(where $\alpha$ is the first component of the final ciphertext and $s_i$ is their secret key). The verifier 
checks the decryption factor's validity using Chaum-Pedersen proofs that prove the discrete log relation 
$\log_g(y_i) = \log_\alpha(d_i)$ (same exponent used for both).
\item Plaintext verification: The plaintext tally is computed from decryption factors and checked for 
consistency: for each candidate position, the prover must verify that $g^{\text{plaintext}} = \text{decrypted value}$, 
which is the final discrete log equality check.
\item Proof of knowledge (POK) checks: Each tallier has published a Schnorr proof of knowledge of their 
secret key, which is verified to ensure key ownership.
\item Public key consistency: The verifier confirms that the product of all talliers' public keys equals 
the election's public key $h = \prod_i y_i$, ensuring no key material was substituted.
\end{enumerate}
\end{itemize}

\textbf{Concrete Parameters}: The verifier is instantiated with cryptographic parameters from actual IACR 
elections stored in [Examples/HeliosTallyIns.v](src/Examples/HeliosTallyIns.v):

\begin{itemize}
\item \textbf{Prime Fields}: 2048-bit prime $p$ and 256-bit prime $q$ (with $p = kq + 1$ for safe prime 
structure), formally verified using the \texttt{primeP} and \texttt{primeQ} modules that establish Znumtheory primality.
\item \textbf{Generators}: The generator $g$ is a Schnorr group element (of order $q$ modulo $p$), 
verified to satisfy $g^q \equiv 1 \pmod{p}$.
\item \textbf{Election Keys}: For the 2024 IACR election (7 candidates), the public key $h_{2024}$ encodes 
election-specific parameters. Alternative instantiations for 2023 and 2022 elections are available but 
commented in the code due to extraction constraints.
\end{itemize}

\textbf{Implementation Details}: The [Executable/HeliosVerifiercode/main.ml](src/Executable/HeliosVerifiercode/main.ml) 
file implements the OCaml interface:

\begin{itemize}
\item Reads JSON ballot data, tallier decryption factors, and proofs from stdin
\item Calls \texttt{compute\_final\_count\_ins}, which executes the formal verification state machine
\item Returns the \texttt{count} proof term (inductive derivation tree) showing all ballots processed correctly
\item Outputs human-readable verification results including:
\begin{itemize}
\item Classification of each ballot as valid/invalid with proof details
\item Intermediate encrypted tallies after each ballot aggregation
\item Final tally statistics (total ballots, valid count, invalid count)
\item Detailed checks on decryption factor validity, plaintext-ciphertext consistency, tallier POKs, 
and public key product verification
\end{itemize}
\end{itemize}

\textbf{Verification Integrity}: The extracted OCaml code inherits the security guarantees from Rocq 
specifications. Each verification step is backed by formal proofs:
\begin{itemize}
\item Ballot processing follows the rules of And-$\Sigma$ composition (verifying multiple disjunctions)
\item Ciphertext aggregation preserves correctness through ElGamal homomorphism
\item Decryption factor validation uses Chaum-Pedersen discrete log equality proofs
\item Plaintext verification reduces to discrete log checking
\item POK verification uses Schnorr protocol soundness
\end{itemize}

The verifier has successfully validated real IACR 2024 election data, demonstrating practical deployment 
of formal verification in privacy-preserving voting systems. The end-to-end verification provides strong 
cryptographic assurance: if any ballot is modified, any decryption factor is forged, or any tally is 
changed, the verifier will detect the corruption.

  


\section{Related Work, Limitations, and Future Work}\label{rel_work}
  Given the popularity of sigma protocol in voting 
  and other domains, it is not surprising that it has 
  been formalised in the past \cite{5552642,9519460,
  butler2021formalising,10.1145/3319535.3354247,287095,almeida2010certifying,10221929,
  10.1145/3594735}. Barthe et al. \cite{5552642}  produced the 
  first first formalisation of sigma protocol and its composition in 
  CertiCrypt, a library developed using the Coq theorem prover. 
  Moreover, their proofs were constructive; however, they 
  did not extract OCaml code to produce an exectuable. 
  Butler et al. \cite{ butler2021formalising} has also 
  formalised sigma protocol in CryptoHOL \cite{10.1007/978-3-662-49498-1_20}, a library 
  build at the top of Isabelle/HOL. Again, similar to  \cite{5552642}, 
  their goal is to machine check sigma protcol and commitment schemes 
  and not extract any executable code. Moreover, Isabellel/HOL admits 
  law of excluded middle and if it is used in formalisation, 
  then no executable code can be extractracted. Haines et al. 
  \cite{287095,10.1145/3319535.3354247} have formalised 
  sigma protocol in the Coq theorem prover and extracted OCaml code 
  to verify the 2020 IACR election and SwissPost mix-network. This is 
  closest to our work; however, their goal is to just verify the 
  election meanwhile our goal is contruct primitive using 
  correct-by-construction principal to conduct election. Moreover, 
  their work lack an intuitive way (probabilistic reasoning) 
  to reason about zero-knowledge. Firsov et al. \cite{10221929}
  have formalised sigma protocol in EasyCrypt, successory 
  of CertiCrypt, but it goal is just machine check 
  the properties of sigma protocol in EascyCrypt 
  and not extract an executable code. 

  
  \subsection{Limitation and Future Work}
   \textcolor{red}{Bas: Some text on extraction to Rust and WebAssembly is not verified?}

   Our formalisation currently lacks mix-network, a crucial cryptographic primitive used 
   in electronic voting. A mix-network is used to break the link between the order of 
   voters and the order of ballots appearing on the election bulletin board. 
   Specifically, a mix-network takes a list of encrypted ballots as input and 
   outputs another list of encrypted ballots in a random order.
   However, since the output is also encrypted, a dishonest mix-network could 
   potentially drop all the original ballots and manifacture artificial ones to favor a 
   particular candidate. To prevent such tampering, the mix-network must also 
   produce a zero-knowledge proof to ensure the correctness of the shuffle \cite{10.1007/978-3-642-02620-1_28,10.1007/978-3-030-51280-4_3}.
   Given our current infrastructure, it would be fairly straightforward to 
   encode these algorithms and prove their security properties. 
   

   Another limitation of our work is 
   that we have formalised the interactive version 
   of sigma protocol and proved it correctness. However, 
   in reality the interaction is removed by 
   using a hash function. Ideally, one would like 
   to formalise the security of sigma protocol in random oracle 
   model, the closest we can get. This means that under the assumption 
   that the hash function behaves as a random oracle, the non-interactive 
   proof derived from the Fiat-Shamir transform is secure. 
   The random oracle model provides a framework where we can 
   reason about the security properties  of 
   the transform. There is an existing 
   work about formalising random oracle in the Coq theorem 
   prover \cite{10.1007/11617990_3} and we would like to 
   connect it our implementation; however, it 
   will require some non-trivial work. 
   
   
  In general, voting is a well-defined protocol formalised in terms 
  message exchanges between a client machine (voter) and a server machine (voting server), 
  and the cryptographic primitives we developed in this project typically operate on 
  a client machine (voter) and a server machine (voting server). 
  However, the correctness of the cryptographic primitives does not imply the 
  correctness of the whole voting system (protocol). Therefore, we aim to develop 
  a high-level API for client-server communication, making their interactions explicit 
  using session types \cite{10.1145/3453483.3454041}. 
  This approach would provide an end-to-end guarantee for the interaction 
  between clients and server in the voting system. 

 

  In this paper, we present a certified implementation 
  that can be readily used by voting community and 
  we demonstrated the usefulness by encoding Helios, 
  Belenois, and SwissPost using our primitives. 
  Moreover, our formalisation extracts to WebAssembly and 
  Rust without duplicate efforts. 





%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{reference}


%%
%% If your work has an appendix, this is the place to put it.
%\appendix

\end{document}
\endinput
%%
%% End of file `sample-sigplan.tex'.
